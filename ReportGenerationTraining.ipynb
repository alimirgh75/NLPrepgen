{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning\n",
    "!pip install transformers\n",
    "!pip install pretrainedmodels\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from torchvision import transforms, models\n",
    "from torch.cuda.amp import GradScaler\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "#from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from random import choice\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from UtilDataset import Label2Arr, MultiLabel\n",
    "from ModelsEncoder import Resnext50, SwinT\n",
    "\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(args, remove = None):\n",
    "    #### 2022 ####\n",
    "    \n",
    "    ##read_data\n",
    "    #clef2022_train_path = '/home/mir/Notebooks/clef2022/Train'\n",
    "    #clef2022_valid_path = '/home/mir/Notebooks/clef2022/Valid'\n",
    "    #clef2022_path = '/home/mir/Notebooks/clef2022'\n",
    "    \n",
    "    clef2022_train_path = '/hdd2/datasets/ImageClef2022medCaption/clef2022/Train'\n",
    "    clef2022_valid_path = '/hdd2/datasets/ImageClef2022medCaption/clef2022/Valid'\n",
    "    clef2022_path = '/hdd2/datasets/ImageClef2022medCaption/clef2022'\n",
    "    traindf2022 = pd.read_csv(os.path.join(clef2022_train_path, 'concept_detection_train.csv'),sep = '\\t')\n",
    "    validdf2022 = pd.read_csv(os.path.join(clef2022_valid_path, 'concept_detection_valid.csv'),sep = '\\t')\n",
    "    concepts = pd.read_csv(os.path.join('/hdd2/datasets/ImageClef2022medCaption/clef2022/concepts.csv'),sep = '\\t')\n",
    "    cuis = concepts['concept'].to_list()\n",
    "    #labels = torch.from_numpy(np.asarray(labels)) \n",
    "    #concept_names = pd.DataFrame(concepts, columns = \"concept_name\")\n",
    "    \n",
    "    #Add img address to ID\n",
    "    traindf2022['ID'] = traindf2022['ID'].apply(lambda x: os.path.join(clef2022_train_path, 'train', x + '.jpg'))\n",
    "    validdf2022['ID'] = validdf2022['ID'].apply(lambda x: os.path.join(clef2022_valid_path, 'valid', x + '.jpg'))\n",
    "    #testdf2022['ID'] = testdf2022['ID'].apply(lambda x: os.path.join(clef2022_path, 'Test_images', x + '.jpg'))\n",
    "    #concat\n",
    "    #train_df = traindf2022\n",
    "    #half_df = len(validdf2022) // 2\n",
    "    #valid_df = validdf2022.iloc[:half_df,]\n",
    "    #test_df = validdf2022.iloc[half_df:,]\n",
    "    #valid_df = validdf2022\n",
    "    #test_df = validdf2022\n",
    "    totaldf2022 = pd.concat([traindf2022,validdf2022])\n",
    "    train_df,rest_df = train_test_split(totaldf2022, train_size=0.8, shuffle= False)\n",
    "    train_df.reset_index(inplace = True, drop = True)\n",
    "    rest_df.reset_index(inplace = True, drop = True)\n",
    "    valid_df,test_df = train_test_split(rest_df, train_size=0.5, shuffle= False)\n",
    "    \n",
    "    valid_df.reset_index(inplace = True, drop = True)\n",
    "    test_df.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    \n",
    "    return train_df, valid_df, test_df, cuis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Label2Arr(cap_list, cuis):\n",
    "    labels = list(itertools.repeat(0, len(cuis)))\n",
    "    for i in cap_list:\n",
    "        for idx,cap in enumerate(cuis):\n",
    "            if cap == i:\n",
    "                labels[idx] = 1\n",
    "    \n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "#from utils import seed_everything, Model, VQAMed, train_one_epoch, validate, test, load_data, LabelSmoothing, train_img_only, val_img_only, test_img_only\n",
    "#import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchvision import transforms, models\n",
    "from torch.cuda.amp import GradScaler\n",
    "import os\n",
    "import warnings\n",
    "import albumentations as A\n",
    "import pretrainedmodels\n",
    "from albumentations.core.composition import OneOf\n",
    "#from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['-f']\n",
    "\n",
    "parser = argparse.ArgumentParser(description = \"args for 2022 ImageCap\")\n",
    "\n",
    "parser.add_argument('--run_name', type = str, required = False, default = \"resnet52FFNN-05-1e-3\", help = \"run name for wandb\")\n",
    "parser.add_argument('--use_pretrained', action = 'store_true', default = False, help = \"use pretrained weights or not\")\n",
    "parser.add_argument('--mixed_precision', action = 'store_true', default = False, help = \"use mixed precision or not\")\n",
    "parser.add_argument('--clip', action = 'store_true', default = False, help = \"clip the gradients or not\")\n",
    "parser.add_argument('--resume', action='store_true', required = False, default = True,  help='resume training or train from scratch')\n",
    "\n",
    "parser.add_argument('--seed', type = int, required = False, default = 42, help = \"set seed for reproducibility\")\n",
    "#parser.add_argument('--cuis', type = int, required = False, default = 42, help = \"set seed for reproducibility\")\n",
    "parser.add_argument('--num_workers', type = int, required = False, default = 1, help = \"number of workers\")\n",
    "parser.add_argument('--epochs', type = int, required = False, default = 100, help = \"num epochs to train\")\n",
    "parser.add_argument('--train_pct', type = float, required = False, default = 1.0, help = \"fraction of train samples to select\")\n",
    "parser.add_argument('--valid_pct', type = float, required = False, default = 1.0, help = \"fraction of validation samples to select\")\n",
    "parser.add_argument('--test_pct', type = float, required = False, default = 1.0, help = \"fraction of test samples to select\")\n",
    "\n",
    "\n",
    "parser.add_argument('--batch_size', type = int, required = False, default = 4, help = \"batch size\")\n",
    "parser.add_argument('--lr', type = float, required = False, default = 1e-3, help = \"learning rate'\")\n",
    "# parser.add_argument('--weight_decay', type = float, required = False, default = 1e-2, help = \" weight decay for gradients\")\n",
    "parser.add_argument('--factor', type = float, required = False, default = 0.1, help = \"factor for rlp\")\n",
    "parser.add_argument('--patience', type = int, required = False, default = 10, help = \"patience for rlp\")\n",
    "# parser.add_argument('--lr_min', type = float, required = False, default = 1e-6, help = \"minimum lr for Cosine Annealing\")\n",
    "parser.add_argument('--hidden_dropout_prob', type = float, required = False, default = 0.3, help = \"hidden dropout probability\")\n",
    "parser.add_argument('--smoothing', type = float, required = False, default = None, help = \"label smoothing\")\n",
    "\n",
    "parser.add_argument('--image_size', type = int, required = False, default = 224, help = \"image size\")\n",
    "parser.add_argument('--threshold', type = float, required = False, default = 0.5 , help = \"image size\")\n",
    "parser.add_argument('--hidden_size', type = int, required = False, default = 768, help = \"hidden size\") #og 312\n",
    "parser.add_argument('--vocab_size', type = int, required = False, default = 30522, help = \"vocab size\")\n",
    "parser.add_argument('--type_vocab_size', type = int, required = False, default = 2, help = \"type vocab size\")\n",
    "parser.add_argument('--heads', type = int, required = False, default = 12, help = \"heads\")\n",
    "parser.add_argument('--n_layers', type = int, required = False, default = 4, help = \"num of layers\")\n",
    "parser.add_argument('--num_vis', type = int, required = False , default = 5, help = \"num of visual embeddings\") #num of conv2d Layers in the transformer, can be: 5, 3 or 1\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "#wandb.init(project='medvqa', name = args.run_name, config = args)\n",
    "\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(loader, model, optimizer, criterion, device, scaler, args):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    PREDS = []\n",
    "    TARGETS = []\n",
    "    bar = tqdm(loader, leave = False)\n",
    "    for (img, target) in bar:\n",
    "        img,target = img.to(device), target.to(device)\n",
    "        loss_func = criterion\n",
    "        optimizer.zero_grad()#step??\n",
    "        logits = model(img)\n",
    "        loss = loss_func(logits, target)    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        TARGETS.append(target)    \n",
    "        pred = logits.detach()\n",
    "        PREDS.append(pred)\n",
    "        \n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_np)\n",
    "        bar.set_description('train_loss: %.5f' % (loss_np))\n",
    "    \n",
    "    acc = 0\n",
    "    PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "    TARGETS = torch.cat(TARGETS).cpu().numpy()\n",
    "    \n",
    "    #PREDS = np.array(PREDS > args.threshold, dtype=float)\n",
    "\n",
    "    #acc = (PREDS == TARGETS).mean() * 100.\n",
    "\n",
    "    return np.mean(train_loss), PREDS, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loader, model, criterion, device, scaler, args):\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    PREDS = []\n",
    "    TARGETS = []\n",
    "    bar = tqdm(loader, leave=False)\n",
    "    #with torch.no_grad():\n",
    "    for (img, target) in bar:\n",
    "        img, target = img.to(device), target.to(device)\n",
    "        if args.mixed_precision:\n",
    "            with torch.cuda.amp.autocast(): \n",
    "                logits = model(img)\n",
    "                loss = criterion(logits, target)\n",
    "        else:\n",
    "            logits = model(img)\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "\n",
    "        pred = logits.detach()\n",
    "\n",
    "        PREDS.append(pred)\n",
    "        TARGETS.append(target)\n",
    "        val_loss.append(loss_np)\n",
    "        bar.set_description('val_loss: %.5f' % (loss_np))\n",
    "    \n",
    "    val_loss = np.mean(val_loss)\n",
    "    acc = 0\n",
    "\n",
    "    PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "    TARGETS = torch.cat(TARGETS).cpu().numpy()\n",
    "    \n",
    "    #PREDS = np.array(PREDS > args.threshold, dtype=float)\n",
    "\n",
    "    #acc = (PREDS == TARGETS).mean() * 100.\n",
    "    return val_loss, PREDS, acc   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, criterion, device, scaler, args):\n",
    "    \n",
    "    model.eval()\n",
    "    TARGETS = []\n",
    "    PREDS = []\n",
    "    test_loss = []\n",
    "    for (img, target) in tqdm(loader, leave=False):\n",
    "        img, target = img.to(device), target.to(device)   \n",
    "        if args.mixed_precision:\n",
    "            with torch.cuda.amp.autocast(): \n",
    "                logits = model(img)\n",
    "                loss = criterion(logits, target)\n",
    "        else:\n",
    "            logits = model(img)\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "\n",
    "        test_loss.append(loss_np)\n",
    "\n",
    "        pred = logits.detach()\n",
    "            \n",
    "        PREDS.append(pred)\n",
    "        TARGETS.append(target)\n",
    "                \n",
    "\n",
    "    test_loss = np.mean(test_loss)\n",
    "    acc =0\n",
    "    PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "    TARGETS = torch.cat(TARGETS).cpu().numpy()\n",
    "    #PREDS = np.array(PREDS > args.threshold, dtype=float)\n",
    "\n",
    "    #acc = (PREDS == TARGETS).mean() * 100.\n",
    "    return test_loss, PREDS, acc, TARGETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change this to switch between datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df, cuis = load_all_data(args)\n",
    "\n",
    "train_tfm = transforms.Compose([transforms.ToPILImage(),\n",
    "                                transforms.RandomResizedCrop(224,scale=(0.75,1.25),ratio=(0.75,1.25)),\n",
    "                                transforms.RandomRotation(10),\n",
    "                                # Cutout(),\n",
    "                                transforms.ColorJitter(brightness=0.4,contrast=0.4,saturation=0.4,hue=0.4),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "val_tfm = transforms.Compose([transforms.ToPILImage(),\n",
    "                              transforms.Resize((224,224)),\n",
    "                              transforms.ToTensor(), \n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_tfm = transforms.Compose([transforms.ToPILImage(),\n",
    "                               transforms.Resize((224,224)),    \n",
    "                               transforms.ToTensor(), \n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "traindataset = MultiLabel(train_df, cuis, imgsize = args.image_size, tfm = train_tfm, args = args)\n",
    "valdataset = MultiLabel(val_df, cuis, imgsize = args.image_size, tfm = val_tfm, args = args)\n",
    "testdataset = MultiLabel(test_df, cuis, imgsize = args.image_size, tfm = test_tfm, args = args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(traindataset, batch_size = args.batch_size, shuffle=True, num_workers = args.num_workers)\n",
    "validloader = DataLoader(valdataset, batch_size = args.batch_size, shuffle=False, num_workers = args.num_workers)\n",
    "testloader = DataLoader(testdataset, batch_size = args.batch_size, shuffle=False, num_workers = args.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinT(len(cuis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "best_acc = 0\n",
    "best_loss = np.inf\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "max_epoch_number = 35\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(),lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=args.lr)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience = args.patience, factor = args.factor, verbose = True)\n",
    "criterion = nn.BCELoss()\n",
    "scaler = GradScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.run_name = \"resnet52FFNN-05-1e-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}')\n",
    "\n",
    "\n",
    "    train_loss, _, train_acc = train_one_epoch(trainloader, model, optimizer, criterion, device, scaler, args)\n",
    "    val_loss, val_predictions, val_acc = validate(validloader, model, criterion, device, scaler, args)\n",
    "    test_loss, test_predictions, test_acc, test_targets = test(testloader, model, criterion, device, scaler, args)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(\"val_loss: \" ,val_loss)\n",
    "    print(\"val_acc: \" ,val_acc)\n",
    "    print(\"test_acc: \" ,test_acc)\n",
    "    \n",
    "    f = open(f'{args.run_name}.txt', \"a\")\n",
    "    f.write('\\n\\nepoch ' + str(epoch))\n",
    "    f.write('\\nAccuracy and Loss')\n",
    "    f.write('\\ntrain_acc: ' + str(train_acc) + '   train_loss: ' + str(train_loss) + ',')\n",
    "    f.write('\\nval_acc: ' + str(val_acc) + '   val_loss: ' + str(val_loss) + ',')\n",
    "    f.write('\\ntest_acc: ' + str(test_acc) + '   test_loss: ' + str(test_loss) + ',')\n",
    "    f.write('\\nlearning_rate: ' + str(optimizer.param_groups[0][\"lr\"]))\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        print('Saving model best acc')\n",
    "        f.write('\\nnew best test total acc')\n",
    "        torch.save(model.state_dict(), f'{args.run_name}_bestacc.pt')\n",
    "        best_acc=test_acc\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        print('Saving model best val loss')\n",
    "        f.write('\\nnew best val_loss')\n",
    "        torch.save(model.state_dict(), f'{args.run_name}.pt')\n",
    "        best_loss=val_loss\n",
    "    elif val_loss > best_loss:\n",
    "        print(\"Val_loss stopped decreasing\")\n",
    "        break\n",
    "            \n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5abb87860b63c959332d2a03a810de3185af3aeaba9fa078f00008040e2d7080"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
